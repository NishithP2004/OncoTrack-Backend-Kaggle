{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nishithp/oncotrack-server?scriptVersionId=232010211\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!sudo apt install lshw clpeak -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:00:46.333514Z","iopub.execute_input":"2025-04-03T16:00:46.33371Z","iopub.status.idle":"2025-04-03T16:00:55.552329Z","shell.execute_reply.started":"2025-04-03T16:00:46.33369Z","shell.execute_reply":"2025-04-03T16:00:55.551268Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  pci.ids usb.ids\nThe following NEW packages will be installed:\n  clpeak lshw pci.ids usb.ids\n0 upgraded, 4 newly installed, 0 to remove and 129 not upgraded.\nNeed to get 835 kB of archives.\nAfter this operation, 3,128 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 lshw amd64 02.19.git.2021.06.19.996aaad9c7-2build1 [321 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 pci.ids all 0.0~2022.01.22-1 [251 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb.ids all 2022.04.02-1 [219 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 clpeak amd64 1.1.0-2 [44.8 kB]\nFetched 835 kB in 0s (2,798 kB/s) \u001b[0m\u001b[33m\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\ndebconf: falling back to frontend: Readline\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package lshw.\n(Reading database ... 127400 files and directories currently installed.)\nPreparing to unpack .../lshw_02.19.git.2021.06.19.996aaad9c7-2build1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package pci.ids.\nPreparing to unpack .../pci.ids_0.0~2022.01.22-1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking pci.ids (0.0~2022.01.22-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package usb.ids.\nPreparing to unpack .../usb.ids_2022.04.02-1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking usb.ids (2022.04.02-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package clpeak.\nPreparing to unpack .../clpeak_1.1.0-2_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking clpeak (1.1.0-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up pci.ids (0.0~2022.01.22-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up usb.ids (2022.04.02-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up clpeak (1.1.0-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for man-db (2.10.2-1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Ngrok","metadata":{}},{"cell_type":"code","source":"!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:00:55.55342Z","iopub.execute_input":"2025-04-03T16:00:55.553709Z","iopub.status.idle":"2025-04-03T16:00:56.583618Z","shell.execute_reply.started":"2025-04-03T16:00:55.553685Z","shell.execute_reply":"2025-04-03T16:00:56.582692Z"}},"outputs":[{"name":"stdout","text":"--2025-04-03 16:00:55--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\nResolving bin.equinox.io (bin.equinox.io)... 35.71.179.82, 99.83.220.108, 75.2.60.68, ...\nConnecting to bin.equinox.io (bin.equinox.io)|35.71.179.82|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 9372184 (8.9M) [application/octet-stream]\nSaving to: â€˜ngrok-v3-stable-linux-amd64.tgzâ€™\n\nngrok-v3-stable-lin 100%[===================>]   8.94M  17.0MB/s    in 0.5s    \n\n2025-04-03 16:00:56 (17.0 MB/s) - â€˜ngrok-v3-stable-linux-amd64.tgzâ€™ saved [9372184/9372184]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!sudo tar -xvzf ngrok-v3-stable-linux-amd64.tgz -C /usr/local/bin ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:00:56.584528Z","iopub.execute_input":"2025-04-03T16:00:56.58479Z","iopub.status.idle":"2025-04-03T16:00:56.919871Z","shell.execute_reply.started":"2025-04-03T16:00:56.584766Z","shell.execute_reply":"2025-04-03T16:00:56.918901Z"}},"outputs":[{"name":"stdout","text":"ngrok\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\n\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\ndomain = user_secrets.get_secret(\"NGROK_DOMAIN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:00:56.920886Z","iopub.execute_input":"2025-04-03T16:00:56.921113Z","iopub.status.idle":"2025-04-03T16:00:57.171338Z","shell.execute_reply.started":"2025-04-03T16:00:56.921092Z","shell.execute_reply":"2025-04-03T16:00:57.170705Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install flask\n!pip install pyngrok","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:00:57.171991Z","iopub.execute_input":"2025-04-03T16:00:57.172255Z","iopub.status.idle":"2025-04-03T16:01:06.033186Z","shell.execute_reply.started":"2025-04-03T16:00:57.17223Z","shell.execute_reply":"2025-04-03T16:01:06.03231Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.1.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\nCollecting pyngrok\n  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.3\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!ngrok config add-authtoken $token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:27:58.04884Z","iopub.execute_input":"2025-04-03T16:27:58.049154Z","iopub.status.idle":"2025-04-03T16:27:58.390438Z","shell.execute_reply.started":"2025-04-03T16:27:58.049132Z","shell.execute_reply":"2025-04-03T16:27:58.389508Z"}},"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# run_in_background(f\"ngrok http --host-header=localhost:5000 --domain {domain} 5000\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:01:12.442389Z","iopub.execute_input":"2025-04-03T16:01:12.442642Z","iopub.status.idle":"2025-04-03T16:01:12.446157Z","shell.execute_reply.started":"2025-04-03T16:01:12.44262Z","shell.execute_reply":"2025-04-03T16:01:12.445475Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from pyngrok import ngrok, conf\n\nconf.get_default().region = \"us\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:01:12.447322Z","iopub.execute_input":"2025-04-03T16:01:12.447556Z","iopub.status.idle":"2025-04-03T16:01:12.501684Z","shell.execute_reply.started":"2025-04-03T16:01:12.447525Z","shell.execute_reply":"2025-04-03T16:01:12.500884Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Unsloth","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:01:12.502549Z","iopub.execute_input":"2025-04-03T16:01:12.502782Z","iopub.status.idle":"2025-04-03T16:05:09.473017Z","shell.execute_reply.started":"2025-04-03T16:01:12.502755Z","shell.execute_reply":"2025-04-03T16:05:09.471802Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport subprocess\nimport json\nfrom flask import Flask, request, jsonify\nfrom unsloth import FastLanguageModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:05:09.474356Z","iopub.execute_input":"2025-04-03T16:05:09.474691Z","iopub.status.idle":"2025-04-03T16:05:44.631649Z","shell.execute_reply.started":"2025-04-03T16:05:09.474658Z","shell.execute_reply":"2025-04-03T16:05:44.630945Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def run_in_background(s):\n    subprocess.Popen(s.split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:05:44.632334Z","iopub.execute_input":"2025-04-03T16:05:44.632539Z","iopub.status.idle":"2025-04-03T16:05:44.636176Z","shell.execute_reply.started":"2025-04-03T16:05:44.632521Z","shell.execute_reply":"2025-04-03T16:05:44.635272Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Pulling the Fine Tuned Model from Hugging Face","metadata":{}},{"cell_type":"code","source":"model_name = \"tsa_oral_cancer_data_extraction_Meta-Llama-3.1-8B-bnb-4bit_10e\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:05:44.636946Z","iopub.execute_input":"2025-04-03T16:05:44.637134Z","iopub.status.idle":"2025-04-03T16:05:44.657233Z","shell.execute_reply.started":"2025-04-03T16:05:44.637117Z","shell.execute_reply":"2025-04-03T16:05:44.656611Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"max_seq_length = 14336 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:05:44.657986Z","iopub.execute_input":"2025-04-03T16:05:44.658186Z","iopub.status.idle":"2025-04-03T16:05:44.672806Z","shell.execute_reply.started":"2025-04-03T16:05:44.658169Z","shell.execute_reply":"2025-04-03T16:05:44.672191Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=f\"NishithP2004/{model_name}\",  # YOUR MODEL YOU USED FOR TRAINING\n        max_seq_length=max_seq_length,\n        dtype=dtype,\n        load_in_4bit=load_in_4bit\n    )\nFastLanguageModel.for_inference(model)  # Enable native 2x faster inference","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:05:44.673733Z","iopub.execute_input":"2025-04-03T16:05:44.67403Z","iopub.status.idle":"2025-04-03T16:06:12.660327Z","shell.execute_reply.started":"2025-04-03T16:05:44.673998Z","shell.execute_reply":"2025-04-03T16:06:12.659594Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"529d597666cd4f0db135a1b63c0e5dc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/235 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fab8732010a4af8b90ab4e8ae4f0d5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc055566160f48339dd06a5e29f91d9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f80a787ecdb476dad99afe879d2f7a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02811c775ec14a1dac5cbb43b3c953ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"306e880ff64e4d45a1a28e7793662d88"}},"metadata":{}},{"name":"stderr","text":"Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Alpaca Prompt Template","metadata":{}},{"cell_type":"code","source":"alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:06:12.661165Z","iopub.execute_input":"2025-04-03T16:06:12.661482Z","iopub.status.idle":"2025-04-03T16:06:12.664885Z","shell.execute_reply.started":"2025-04-03T16:06:12.661447Z","shell.execute_reply":"2025-04-03T16:06:12.664039Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"instruction = \"Extract the essential details from the provided text containing a patientâ€™s oral cancer data. Format the output as a semi-colon separated list of key-value pairs, strictly adhering to the following structure:\\nfeature1:value1;feature2:value2;â€¦ \\nExample: age:40;sex:1;subsite:2;Pathology:3;â€¦ \\nEnsure precise and efficient extraction by applying the given mappings accurately.\\nMappings: 1. age\\n2. sex: {male: 1, female: 2}\\n3. subsite: {tongue: 1, BM: 2, FOM: 3, alveolus: 4, hard palate: 5, RMT: 6, lips: 7}\\n4. pathology: {WDSCC: 1, Verrucous: 2, MDSCC: 3, PDSCC: 4, others: 5, ca in situ: 6}\\n5. clinicalT8thed: {T1: 1, T2: 2, T3: 3, T4a: 4, T4b: 5}\\n6. nodal8thed: {No nodes: 0, N1: 1, N2a: 2, N2b: 3, N2c: 4, N3a: 5, N3b: 6}\\n7. pt8thed: {T1: 1, T2: 2, T3: 3, T4a: 4, T4b: 5}\\n8. pN8thed: {N0: 0, N1: 1, N2a: 2, N2b: 3, N2c: 4, N3a: 5, N3b: 6}\\n9. PNI: {no: 0, yes: 1}\\n10. LVI: {no: 0, yes: 1}\\n11. Margins: {negative: 0, close: 1, positive: 2}\\n12. Boneinv: {no: 0, yes: 1}\\n13. skininv: {no: 0, yes: 1}\\n14. ENS: {no: 0, yes: 1}\\n15. Surgery: {SND 1-3: 1, SND 1-4: 2, MRND: 3, RND: 4}\\n16. lateralitysurgery: {ipsilateral: 1, bilateral: 2}\\n17. DOS\\n18. adjRx: {no: 0, yes: 1}\\n19. date of LR\\n20. Nodalrecurrencelevel: {ipsilateral: 1, contralateral: 2}\\n21. Nodallevel\\n22. date of Nodalrecurrence\\n23. last FU\\n24. stateFU: {NED: 1, AWD: 2, DWD': 3, Dead due to other causes: 4}\\nFullforms \\n1. BM â€“ Buccal Mucosa\\n2. FOM â€“ Floor of Mouth\\n3. RMT â€“ Retromolar Trigone\\n4. WDSCC â€“ Well-Differentiated Squamous Cell Carcinoma\\n5. MDSCC â€“ Moderately Differentiated Squamous Cell Carcinoma\\n6. PDSCC â€“ Poorly Differentiated Squamous Cell Carcinoma\\n7. PNI â€“ Perineural Invasion\\n8. LVI â€“ Lymphovascular Invasion\\n9. ENS â€“ Extracapsular Nodal Spread\\n10. SND â€“ Selective Neck Dissection\\n11. MRND â€“ Modified Radical Neck Dissection\\n12. RND â€“ Radical Neck Dissection\\n13. DOS â€“ Date of Surgery\\n14. adjRx â€“ Adjuvant Therapy\\n15. date of LR â€“ Date of Local Recurrence\\n16. last FU â€“ Date of Last Follow-Up\\n17. state FU â€“ State at Last Follow-Up\\n18. Verrucous - Verrucous Carcinoma\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:06:12.665776Z","iopub.execute_input":"2025-04-03T16:06:12.666011Z","iopub.status.idle":"2025-04-03T16:06:21.525149Z","shell.execute_reply.started":"2025-04-03T16:06:12.665989Z","shell.execute_reply":"2025-04-03T16:06:21.524449Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:06:21.526018Z","iopub.execute_input":"2025-04-03T16:06:21.526344Z","iopub.status.idle":"2025-04-03T16:06:21.545627Z","shell.execute_reply.started":"2025-04-03T16:06:21.52631Z","shell.execute_reply":"2025-04-03T16:06:21.545027Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\n\ndef process_output(output_string):\n    \"\"\"Processes a single output string, splitting by ';' and then ':'.\n    Returns a dictionary with key-value pairs from the string.\n    \"\"\"\n    result = {}\n    if pd.isna(output_string) or output_string == '': # handle missing or empty strings\n        return result\n\n    for item in output_string.split(';'):\n        try:\n            key, value = item.split(':', 1)  # Split at the first ':'\n            result[key.strip()] = value.strip()\n        except ValueError:  # Handle cases where there's no ':'\n            print(f\"Skipping malformed item: {item}\")\n    return result\n\ndef process_model_output(output_string):\n    \"\"\"Extracts the response from the model's generated output.\"\"\"\n    try:\n        print(\"Output: \", output_string)\n        output_string = output_string.split(\"### Response:\\n\")[1].split(EOS_TOKEN)[0]\n    except IndexError:\n        print(\"Warning: Unexpected output format. Returning empty dictionary.\")\n        return {}\n    return process_output(output_string)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:06:21.546446Z","iopub.execute_input":"2025-04-03T16:06:21.546775Z","iopub.status.idle":"2025-04-03T16:06:21.562865Z","shell.execute_reply.started":"2025-04-03T16:06:21.546752Z","shell.execute_reply":"2025-04-03T16:06:21.562064Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Flask Server","metadata":{}},{"cell_type":"code","source":"# Define Flask app\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef index():\n    return \"Hello from Kaggle!\"\n\ndef generate_response(text):\n    input_text = alpaca_prompt.format(instruction, text, \"\")\n    inputs = tokenizer([input_text], return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    outputs = model.generate(**inputs, max_new_tokens=256, use_cache=True)\n    generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n    result_dict = process_model_output(generated_text)\n    print(result_dict)\n    return result_dict\n\n@app.route('/extract', methods=['POST'])\ndef extract():\n    data = request.get_json()\n    if not data or 'text' not in data:\n        return jsonify({\"error\": \"Invalid input. Expected JSON with 'text' field.\"}), 400\n    response = generate_response(data['text'])\n    return jsonify({\"response\": response})\n\n# Run Flask server in the background\ndef run_flask():\n    public_url = ngrok.connect(5000, domain=domain).public_url\n    print(f\" * Ngrok Tunnel: {public_url}\")\n    app.run(host=\"0.0.0.0\", port=5000)\n\n\nif __name__ == '__main__':\n    run_flask()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:28:05.140029Z","iopub.execute_input":"2025-04-03T16:28:05.140409Z","execution_failed":"2025-04-03T16:31:51.686Z"},"scrolled":true},"outputs":[{"name":"stdout","text":" * Ngrok Tunnel: https://dominant-usually-oyster.ngrok-free.app\n * Serving Flask app '__main__'\n * Debug mode: off\nOutput:  Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nExtract the essential details from the provided text containing a patientâ€™s oral cancer data. Format the output as a semi-colon separated list of key-value pairs, strictly adhering to the following structure:\nfeature1:value1;feature2:value2;â€¦ \nExample: age:40;sex:1;subsite:2;Pathology:3;â€¦ \nEnsure precise and efficient extraction by applying the given mappings accurately.\nMappings: 1. age\n2. sex: {male: 1, female: 2}\n3. subsite: {tongue: 1, BM: 2, FOM: 3, alveolus: 4, hard palate: 5, RMT: 6, lips: 7}\n4. pathology: {WDSCC: 1, Verrucous: 2, MDSCC: 3, PDSCC: 4, others: 5, ca in situ: 6}\n5. clinicalT8thed: {T1: 1, T2: 2, T3: 3, T4a: 4, T4b: 5}\n6. nodal8thed: {No nodes: 0, N1: 1, N2a: 2, N2b: 3, N2c: 4, N3a: 5, N3b: 6}\n7. pt8thed: {T1: 1, T2: 2, T3: 3, T4a: 4, T4b: 5}\n8. pN8thed: {N0: 0, N1: 1, N2a: 2, N2b: 3, N2c: 4, N3a: 5, N3b: 6}\n9. PNI: {no: 0, yes: 1}\n10. LVI: {no: 0, yes: 1}\n11. Margins: {negative: 0, close: 1, positive: 2}\n12. Boneinv: {no: 0, yes: 1}\n13. skininv: {no: 0, yes: 1}\n14. ENS: {no: 0, yes: 1}\n15. Surgery: {SND 1-3: 1, SND 1-4: 2, MRND: 3, RND: 4}\n16. lateralitysurgery: {ipsilateral: 1, bilateral: 2}\n17. DOS\n18. adjRx: {no: 0, yes: 1}\n19. date of LR\n20. Nodalrecurrencelevel: {ipsilateral: 1, contralateral: 2}\n21. Nodallevel\n22. date of Nodalrecurrence\n23. last FU\n24. stateFU: {NED: 1, AWD: 2, DWD': 3, Dead due to other causes: 4}\nFullforms \n1. BM â€“ Buccal Mucosa\n2. FOM â€“ Floor of Mouth\n3. RMT â€“ Retromolar Trigone\n4. WDSCC â€“ Well-Differentiated Squamous Cell Carcinoma\n5. MDSCC â€“ Moderately Differentiated Squamous Cell Carcinoma\n6. PDSCC â€“ Poorly Differentiated Squamous Cell Carcinoma\n7. PNI â€“ Perineural Invasion\n8. LVI â€“ Lymphovascular Invasion\n9. ENS â€“ Extracapsular Nodal Spread\n10. SND â€“ Selective Neck Dissection\n11. MRND â€“ Modified Radical Neck Dissection\n12. RND â€“ Radical Neck Dissection\n13. DOS â€“ Date of Surgery\n14. adjRx â€“ Adjuvant Therapy\n15. date of LR â€“ Date of Local Recurrence\n16. last FU â€“ Date of Last Follow-Up\n17. state FU â€“ State at Last Follow-Up\n18. Verrucous - Verrucous Carcinoma\n\n### Input:\nDate :07/09/2011\n\nProgressNotes :\n\nas per the TB discussion\n\npatient posted for WLE +SEGMENTAL MANDIBULECTOMY+RECONSTYRUCTION  with bone flap +/_ adj treatment\n\nPAc to be seen today\n\nslide review today\n\n### Response:\nage: 62;sex: 1;subsite: 3;Pathology: 3;clinicalT8thed: 3;nodal8thed: 0;pt8thed: 4;pN8thed: 0;PNI: 0;LVI: 0;Margins: 0;Boneinv: 0;skininv: 0;ENS: 0;Surgery: 2;lateralitysurgery: 1;DOS: 9/8/2011;adjRx: 0;dateofLR: ;NodalrecurrenceLevel: ;nodallevel: ;dateofNodalrecurrence: ;lastFU: 7/31/2013;stateFU: 1\n{'age': '62', 'sex': '1', 'subsite': '3', 'Pathology': '3', 'clinicalT8thed': '3', 'nodal8thed': '0', 'pt8thed': '4', 'pN8thed': '0', 'PNI': '0', 'LVI': '0', 'Margins': '0', 'Boneinv': '0', 'skininv': '0', 'ENS': '0', 'Surgery': '2', 'lateralitysurgery': '1', 'DOS': '9/8/2011', 'adjRx': '0', 'dateofLR': '', 'NodalrecurrenceLevel': '', 'nodallevel': '', 'dateofNodalrecurrence': '', 'lastFU': '7/31/2013', 'stateFU': '1'}\n","output_type":"stream"}],"execution_count":null}]}