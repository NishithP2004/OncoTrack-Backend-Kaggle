{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4e65fbd9a974705855efa6825e6edc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e325aaa3ee4081aaf627e46ef162fa",
              "IPY_MODEL_7b8f0ec9acd748a29f2d808cfa3405ac",
              "IPY_MODEL_5464be164b3a4b02b42a56168ada8d3d"
            ],
            "layout": "IPY_MODEL_020d7edb176b4ea6bd2f7e285f14c2cd"
          }
        },
        "63e325aaa3ee4081aaf627e46ef162fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd1a4695e5e47399cb4d4bf9de4785f",
            "placeholder": "​",
            "style": "IPY_MODEL_19da1abbb1674e22b99d406f4ae02249",
            "value": "model.safetensors: 100%"
          }
        },
        "7b8f0ec9acd748a29f2d808cfa3405ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de70fda9bc05473f856e93e91dfcea93",
            "max": 5702746390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34fab13b411d4ef989845be4b9190027",
            "value": 5702745847
          }
        },
        "5464be164b3a4b02b42a56168ada8d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f536cf9e6b3f434fbff86a8129620be0",
            "placeholder": "​",
            "style": "IPY_MODEL_7aee699f25664714a712c36f211c50ec",
            "value": " 5.70G/5.70G [00:15&lt;00:00, 602MB/s]"
          }
        },
        "020d7edb176b4ea6bd2f7e285f14c2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd1a4695e5e47399cb4d4bf9de4785f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19da1abbb1674e22b99d406f4ae02249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de70fda9bc05473f856e93e91dfcea93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34fab13b411d4ef989845be4b9190027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f536cf9e6b3f434fbff86a8129620be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aee699f25664714a712c36f211c50ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2685f2d0828444e39f40dd13c858ab76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c1fbda83f0947219c979e2ed32f80f9",
              "IPY_MODEL_5f085f84f7994d518fc608a4a93e09e1",
              "IPY_MODEL_37a906e90de445b0add0115aa4f8f605"
            ],
            "layout": "IPY_MODEL_dae5a13d521f4c178024f7060c248436"
          }
        },
        "6c1fbda83f0947219c979e2ed32f80f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6d8bf018bb49418142012f550daa52",
            "placeholder": "​",
            "style": "IPY_MODEL_8c8d21e140a2497ba9579b49a0a2fe55",
            "value": "generation_config.json: 100%"
          }
        },
        "5f085f84f7994d518fc608a4a93e09e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b46b315ae64139a1a542b56d899afa",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63760cd1558043d78fc5ca133f31937f",
            "value": 235
          }
        },
        "37a906e90de445b0add0115aa4f8f605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a37bb3101c48a2a8b77fbcb6bbd25e",
            "placeholder": "​",
            "style": "IPY_MODEL_097457c42fcb46eda4d99db97b677b61",
            "value": " 235/235 [00:00&lt;00:00, 29.8kB/s]"
          }
        },
        "dae5a13d521f4c178024f7060c248436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6d8bf018bb49418142012f550daa52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c8d21e140a2497ba9579b49a0a2fe55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25b46b315ae64139a1a542b56d899afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63760cd1558043d78fc5ca133f31937f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52a37bb3101c48a2a8b77fbcb6bbd25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097457c42fcb46eda4d99db97b677b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b637c1fc1cb4946ab44b4eef74a5c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_860b1cdd90a942dc8b0df2fc54b221fc",
              "IPY_MODEL_c7410b0e8a0b49eb9c17ad24ef1ad6ef",
              "IPY_MODEL_28661b4840584e9d86f036952938199c"
            ],
            "layout": "IPY_MODEL_8819a3621a45460cb690f4fdd94cdcf2"
          }
        },
        "860b1cdd90a942dc8b0df2fc54b221fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6c6a6a9be9a43e99a2d35cfbd565136",
            "placeholder": "​",
            "style": "IPY_MODEL_98933a123e94465b9a3f7fc6fbbcfe1b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c7410b0e8a0b49eb9c17ad24ef1ad6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d160616a55e4337b4d2827e13195273",
            "max": 50642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5c84f8669cd454a86ad8a4c8c74c2a3",
            "value": 50642
          }
        },
        "28661b4840584e9d86f036952938199c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af462ecc90134147beafcfea71edccbd",
            "placeholder": "​",
            "style": "IPY_MODEL_3a06fc411c4f449e9efb1ed5d2c4742f",
            "value": " 50.6k/50.6k [00:00&lt;00:00, 4.68MB/s]"
          }
        },
        "8819a3621a45460cb690f4fdd94cdcf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c6a6a9be9a43e99a2d35cfbd565136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98933a123e94465b9a3f7fc6fbbcfe1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d160616a55e4337b4d2827e13195273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c84f8669cd454a86ad8a4c8c74c2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af462ecc90134147beafcfea71edccbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a06fc411c4f449e9efb1ed5d2c4742f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea8edf1350b4567b2c143542b78a8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1816a5775ad42d7818a19d17fdee3d9",
              "IPY_MODEL_97d33642d64940fe8d0abd521bd8aa2b",
              "IPY_MODEL_e6462913bd1c4956b7bc5e77635af957"
            ],
            "layout": "IPY_MODEL_74820137eab141e7aa8cf4476dc4646c"
          }
        },
        "f1816a5775ad42d7818a19d17fdee3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d246dba4a5cf4182a7a33218bc9941f2",
            "placeholder": "​",
            "style": "IPY_MODEL_972d74c8f2aa4cb2901c0e397d931592",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "97d33642d64940fe8d0abd521bd8aa2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed67ed8ce1b4fd5863a8ad68380ee23",
            "max": 459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11293dec18044f0c8ab9b674269925a3",
            "value": 459
          }
        },
        "e6462913bd1c4956b7bc5e77635af957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82f7a99113704175950d8dae8cda8d64",
            "placeholder": "​",
            "style": "IPY_MODEL_90a309b952fd4a228360481355d9d810",
            "value": " 459/459 [00:00&lt;00:00, 59.2kB/s]"
          }
        },
        "74820137eab141e7aa8cf4476dc4646c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d246dba4a5cf4182a7a33218bc9941f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972d74c8f2aa4cb2901c0e397d931592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ed67ed8ce1b4fd5863a8ad68380ee23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11293dec18044f0c8ab9b674269925a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82f7a99113704175950d8dae8cda8d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a309b952fd4a228360481355d9d810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445de90eeaa141f082da3dbb717e17e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_911b30abf4a9408c98bc9d93460d9d67",
              "IPY_MODEL_df41dba975634a5694e78c093d82a980",
              "IPY_MODEL_88033e32340744e5ae26b2a43fce9995"
            ],
            "layout": "IPY_MODEL_a8275ead9eed4a70a4d194ea251885b5"
          }
        },
        "911b30abf4a9408c98bc9d93460d9d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8998e00c56b49f0a8f4f34c0defba98",
            "placeholder": "​",
            "style": "IPY_MODEL_d77116ddd8574c5bbb3068cd191eba1a",
            "value": "tokenizer.json: 100%"
          }
        },
        "df41dba975634a5694e78c093d82a980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_529c9268c58f408dbdf10744fa947ce7",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f285060bdc54a6ab454adb5f557c005",
            "value": 17209920
          }
        },
        "88033e32340744e5ae26b2a43fce9995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7171882dc42f4d5aab693a14c8903883",
            "placeholder": "​",
            "style": "IPY_MODEL_337c7d17afbc418a9a5eb0be1162bc22",
            "value": " 17.2M/17.2M [00:00&lt;00:00, 34.0MB/s]"
          }
        },
        "a8275ead9eed4a70a4d194ea251885b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8998e00c56b49f0a8f4f34c0defba98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d77116ddd8574c5bbb3068cd191eba1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "529c9268c58f408dbdf10744fa947ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f285060bdc54a6ab454adb5f557c005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7171882dc42f4d5aab693a14c8903883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337c7d17afbc418a9a5eb0be1162bc22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf1223c823b04337b306459b38d4ff04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f261e958473441528ab11994f2d03926",
              "IPY_MODEL_df7a0dc53cf74c9aab8a496861405d0f",
              "IPY_MODEL_0c5e8bbc1f96405bb3be3113c21fb2ed"
            ],
            "layout": "IPY_MODEL_66ea58de3d7d4987a07930c8d45cc5fb"
          }
        },
        "f261e958473441528ab11994f2d03926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa8597f96494dc48c8545bb9e5b7d3d",
            "placeholder": "​",
            "style": "IPY_MODEL_4a923ee8e5394cdcbdb2c759fd144e4e",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "df7a0dc53cf74c9aab8a496861405d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aafcebb536b4ffa9cc38b08ec57ce88",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f8b658d79c042319704357927881ba3",
            "value": 167832224
          }
        },
        "0c5e8bbc1f96405bb3be3113c21fb2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a683afcde61445fb2e092ad839d28ee",
            "placeholder": "​",
            "style": "IPY_MODEL_ca725302dccc4b66b41d5ae612e43683",
            "value": " 168M/168M [00:00&lt;00:00, 146MB/s]"
          }
        },
        "66ea58de3d7d4987a07930c8d45cc5fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa8597f96494dc48c8545bb9e5b7d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a923ee8e5394cdcbdb2c759fd144e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aafcebb536b4ffa9cc38b08ec57ce88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8b658d79c042319704357927881ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a683afcde61445fb2e092ad839d28ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca725302dccc4b66b41d5ae612e43683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NishithP2004/OncoTrack-Backend-Kaggle/blob/main/OncoTrack_Server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "H98yJkBsqHcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ollama"
      ],
      "metadata": {
        "id": "eQaEoBKsqHcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install lshw clpeak -y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:22:54.954525Z",
          "iopub.execute_input": "2025-04-07T05:22:54.954834Z",
          "iopub.status.idle": "2025-04-07T05:22:57.34397Z",
          "shell.execute_reply.started": "2025-04-07T05:22:54.954811Z",
          "shell.execute_reply": "2025-04-07T05:22:57.343173Z"
        },
        "scrolled": true,
        "id": "FOVKtCBTqHcq",
        "outputId": "0bab937c-fdc3-40eb-f2f7-baa926834c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  pci.ids usb.ids\n",
            "The following NEW packages will be installed:\n",
            "  clpeak lshw pci.ids usb.ids\n",
            "0 upgraded, 4 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 835 kB of archives.\n",
            "After this operation, 3,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 lshw amd64 02.19.git.2021.06.19.996aaad9c7-2build1 [321 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 pci.ids all 0.0~2022.01.22-1ubuntu0.1 [251 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb.ids all 2022.04.02-1 [219 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 clpeak amd64 1.1.0-2 [44.8 kB]\n",
            "Fetched 835 kB in 0s (2,752 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package lshw.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../lshw_02.19.git.2021.06.19.996aaad9c7-2build1_amd64.deb ...\n",
            "Unpacking lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n",
            "Selecting previously unselected package pci.ids.\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1ubuntu0.1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Selecting previously unselected package usb.ids.\n",
            "Preparing to unpack .../usb.ids_2022.04.02-1_all.deb ...\n",
            "Unpacking usb.ids (2022.04.02-1) ...\n",
            "Selecting previously unselected package clpeak.\n",
            "Preparing to unpack .../clpeak_1.1.0-2_amd64.deb ...\n",
            "Unpacking clpeak (1.1.0-2) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Setting up lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n",
            "Setting up usb.ids (2022.04.02-1) ...\n",
            "Setting up clpeak (1.1.0-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:22:57.345167Z",
          "iopub.execute_input": "2025-04-07T05:22:57.345441Z",
          "iopub.status.idle": "2025-04-07T05:23:35.52444Z",
          "shell.execute_reply.started": "2025-04-07T05:22:57.345405Z",
          "shell.execute_reply": "2025-04-07T05:23:35.523442Z"
        },
        "id": "Wmn6gtWLqHcr",
        "outputId": "1b99d26b-201a-43ad-d863-d0bc07e0be95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OLLAMA_KEEP_ALIVE\"]=\"-1\"\n",
        "os.environ[\"OLLAMA_NUM_PARALLEL\"]=\"4\"\n",
        "os.environ[\"OLLAMA_FLASH_ATTENTION\"]=\"1\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:35.525997Z",
          "iopub.execute_input": "2025-04-07T05:23:35.526253Z",
          "iopub.status.idle": "2025-04-07T05:23:35.530184Z",
          "shell.execute_reply.started": "2025-04-07T05:23:35.52623Z",
          "shell.execute_reply": "2025-04-07T05:23:35.529338Z"
        },
        "id": "wtMs9uCEqHcr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "def run_in_background(s):\n",
        "    subprocess.Popen(s.split())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:35.531291Z",
          "iopub.execute_input": "2025-04-07T05:23:35.531565Z",
          "iopub.status.idle": "2025-04-07T05:23:35.546674Z",
          "shell.execute_reply.started": "2025-04-07T05:23:35.531534Z",
          "shell.execute_reply": "2025-04-07T05:23:35.545933Z"
        },
        "id": "l4PF90WkqHcs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "run_in_background(\"ollama serve\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:48:53.501108Z",
          "iopub.execute_input": "2025-04-07T05:48:53.501436Z",
          "iopub.status.idle": "2025-04-07T05:48:53.506538Z",
          "shell.execute_reply.started": "2025-04-07T05:48:53.501411Z",
          "shell.execute_reply": "2025-04-07T05:48:53.505654Z"
        },
        "id": "q1-pa8T_qHcs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:35.563487Z",
          "iopub.execute_input": "2025-04-07T05:23:35.563826Z",
          "iopub.status.idle": "2025-04-07T05:23:39.515807Z",
          "shell.execute_reply.started": "2025-04-07T05:23:35.563764Z",
          "shell.execute_reply": "2025-04-07T05:23:39.514066Z"
        },
        "id": "fj4mLqKrqHcs",
        "outputId": "91cc00fc-9cd0-44aa-c74c-092d8edd49dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.4.8-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.11.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
            "Downloading ollama-0.4.8-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama\n",
            "Successfully installed ollama-0.4.8\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "\n",
        "# models = [\"gemma3:4b\", \"llama3.2:3b\", \"qwen2.5:3b\", \"phi3.5:3.8b\", \"nemotron-mini:4b\", \"exaone3.5:2.4b\", \"granite3.1-dense:2b\", \"granite3.1-moe:3b\", \"deepseek-r1:1.5b\", \"llama3.2-vision\"]\n",
        "models = [\"gemma3:4b\", \"nomic-embed-text\"]\n",
        "\n",
        "for model in models:\n",
        "    print(f\"[+] Pulling {model}\")\n",
        "    ollama.pull(model)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:39.516924Z",
          "iopub.execute_input": "2025-04-07T05:23:39.517254Z",
          "iopub.status.idle": "2025-04-07T05:23:40.401699Z",
          "shell.execute_reply.started": "2025-04-07T05:23:39.517227Z",
          "shell.execute_reply": "2025-04-07T05:23:40.400999Z"
        },
        "id": "LCxUSGP7qHcs",
        "outputId": "246812d3-32f9-4398-db25-4ac1b4798169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Pulling gemma3:4b\n",
            "[+] Pulling nomic-embed-text\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Langchain + ChromaDB"
      ],
      "metadata": {
        "id": "piZ4_9mVsclB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-ollama langchain-chroma -q\n",
        "!pip install chromadb -q"
      ],
      "metadata": {
        "id": "ybFtYhaXsmt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d592dea-0729-4759-86e5-35abe3e33205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured uuid -q"
      ],
      "metadata": {
        "id": "EEfar_cqsnat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1bbf3d4-6b2d-4b7b-b543-60f5a4242708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ngrok"
      ],
      "metadata": {
        "id": "Y3yn555WqHcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:40.403978Z",
          "iopub.execute_input": "2025-04-07T05:23:40.404228Z",
          "iopub.status.idle": "2025-04-07T05:23:44.879917Z",
          "shell.execute_reply.started": "2025-04-07T05:23:40.404208Z",
          "shell.execute_reply": "2025-04-07T05:23:44.879118Z"
        },
        "id": "7aWU7hM1qHct",
        "outputId": "b4c5960f-3d41-4de0-d30f-e0883f392bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-18 16:11:46--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 13.248.244.96, 75.2.60.68, 35.71.179.82, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|13.248.244.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9395172 (9.0M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-v3-stable-linux-amd64.tgz’\n",
            "\n",
            "ngrok-v3-stable-lin 100%[===================>]   8.96M  18.1MB/s    in 0.5s    \n",
            "\n",
            "2025-05-18 16:11:47 (18.1 MB/s) - ‘ngrok-v3-stable-linux-amd64.tgz’ saved [9395172/9395172]\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo tar -xvzf ngrok-v3-stable-linux-amd64.tgz -C /usr/local/bin"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:44.88162Z",
          "iopub.execute_input": "2025-04-07T05:23:44.881854Z",
          "iopub.status.idle": "2025-04-07T05:23:45.248891Z",
          "shell.execute_reply.started": "2025-04-07T05:23:44.881833Z",
          "shell.execute_reply": "2025-04-07T05:23:45.248024Z"
        },
        "id": "gWgjaRKpqHct",
        "outputId": "1b89adce-a2ec-4c5c-ce9a-e980f58a00b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "''' from kaggle_secrets import UserSecretsClient\n",
        "import os\n",
        "\n",
        "user_secrets = UserSecretsClient()\n",
        "token = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\n",
        "domain = user_secrets.get_secret(\"NGROK_DOMAIN\") '''"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:45.250041Z",
          "iopub.execute_input": "2025-04-07T05:23:45.250436Z",
          "iopub.status.idle": "2025-04-07T05:23:45.550854Z",
          "shell.execute_reply.started": "2025-04-07T05:23:45.250395Z",
          "shell.execute_reply": "2025-04-07T05:23:45.549981Z"
        },
        "id": "v_llYRWPqHct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7854a0b0-0182-4ec4-c5e3-4b24834f7673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' from kaggle_secrets import UserSecretsClient\\nimport os\\n\\nuser_secrets = UserSecretsClient()\\ntoken = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\\ndomain = user_secrets.get_secret(\"NGROK_DOMAIN\") '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "token = userdata.get(\"NGROK_AUTH_TOKEN\")\n",
        "domain = userdata.get(\"NGROK_DOMAIN\")"
      ],
      "metadata": {
        "id": "j5t1tvE5rSPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-socketio pyngrok"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:45.551846Z",
          "iopub.execute_input": "2025-04-07T05:23:45.5521Z",
          "iopub.status.idle": "2025-04-07T05:23:49.13823Z",
          "shell.execute_reply.started": "2025-04-07T05:23:45.552043Z",
          "shell.execute_reply": "2025-04-07T05:23:49.137204Z"
        },
        "id": "hwj6BJpvqHct",
        "outputId": "328a5e25-e7cc-471e-928f-5951431ed898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-socketio\n",
            "  Downloading Flask_SocketIO-5.5.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Collecting python-socketio>=5.12.0 (from flask-socketio)\n",
            "  Downloading python_socketio-5.13.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Collecting bidict>=0.21.0 (from python-socketio>=5.12.0->flask-socketio)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting python-engineio>=4.11.0 (from python-socketio>=5.12.0->flask-socketio)\n",
            "  Downloading python_engineio-4.12.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio)\n",
            "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (0.16.0)\n",
            "Downloading Flask_SocketIO-5.5.1-py3-none-any.whl (18 kB)\n",
            "Downloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n",
            "Downloading python_socketio-5.13.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading python_engineio-4.12.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, pyngrok, bidict, simple-websocket, python-engineio, python-socketio, flask-socketio\n",
            "Successfully installed bidict-0.23.1 flask-socketio-5.5.1 pyngrok-7.2.8 python-engineio-4.12.1 python-socketio-5.13.0 simple-websocket-1.1.0 wsproto-1.2.0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken $token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:49.13934Z",
          "iopub.execute_input": "2025-04-07T05:23:49.139705Z",
          "iopub.status.idle": "2025-04-07T05:23:49.28025Z",
          "shell.execute_reply.started": "2025-04-07T05:23:49.139664Z",
          "shell.execute_reply": "2025-04-07T05:23:49.279253Z"
        },
        "id": "zGqoJDZvqHct",
        "outputId": "8bf54d1d-9c0d-467f-80df-7aeb9b9cae92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# run_in_background(f\"ngrok http --host-header=localhost:5000 --domain {domain} 5000\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:49.281204Z",
          "iopub.execute_input": "2025-04-07T05:23:49.28146Z",
          "iopub.status.idle": "2025-04-07T05:23:49.285031Z",
          "shell.execute_reply.started": "2025-04-07T05:23:49.281436Z",
          "shell.execute_reply": "2025-04-07T05:23:49.284124Z"
        },
        "id": "P7UHPxiKqHct"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "\n",
        "conf.get_default().region = \"us\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:49.285733Z",
          "iopub.execute_input": "2025-04-07T05:23:49.285951Z",
          "iopub.status.idle": "2025-04-07T05:23:49.320026Z",
          "shell.execute_reply.started": "2025-04-07T05:23:49.285932Z",
          "shell.execute_reply": "2025-04-07T05:23:49.319279Z"
        },
        "id": "6Oou0Kg7qHct"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open AI Whisper"
      ],
      "metadata": {
        "id": "nj4jIrS_qHct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:49.320835Z",
          "iopub.execute_input": "2025-04-07T05:23:49.3211Z",
          "iopub.status.idle": "2025-04-07T05:23:53.01827Z",
          "shell.execute_reply.started": "2025-04-07T05:23:49.321071Z",
          "shell.execute_reply": "2025-04-07T05:23:53.017177Z"
        },
        "id": "351zBAN8qHct",
        "outputId": "7b7c06cc-fbb5-43d0-a713-dc55e5c50a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/800.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=ce56a10c7045e3dc5a919ba4b83bd448593655d0d633814ea4c69ae324297b47\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:53.019403Z",
          "iopub.execute_input": "2025-04-07T05:23:53.019674Z",
          "iopub.status.idle": "2025-04-07T05:23:58.081551Z",
          "shell.execute_reply.started": "2025-04-07T05:23:53.019643Z",
          "shell.execute_reply": "2025-04-07T05:23:58.080391Z"
        },
        "id": "foy-AcqiqHct",
        "outputId": "dcf8f253-439c-4e58-8cce-1a5676e4fd77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 14.2 kB/129\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,725 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,944 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 30.6 MB in 2s (14.0 MB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "89 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 89 not upgraded.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools-rust"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:23:58.082752Z",
          "iopub.execute_input": "2025-04-07T05:23:58.083043Z",
          "iopub.status.idle": "2025-04-07T05:24:01.744702Z",
          "shell.execute_reply.started": "2025-04-07T05:23:58.083015Z",
          "shell.execute_reply": "2025-04-07T05:24:01.743859Z"
        },
        "id": "gbFKOrDYqHct",
        "outputId": "d770acf7-d2f1-4bee-a410-087215f92062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting setuptools-rust\n",
            "  Downloading setuptools_rust-1.11.1-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.11/dist-packages (from setuptools-rust) (75.2.0)\n",
            "Collecting semantic_version<3,>=2.8.2 (from setuptools-rust)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Downloading setuptools_rust-1.11.1-py3-none-any.whl (28 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: semantic_version, setuptools-rust\n",
            "Successfully installed semantic_version-2.10.0 setuptools-rust-1.11.1\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "whisper_model = whisper.load_model(\"turbo\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:24:01.745813Z",
          "iopub.execute_input": "2025-04-07T05:24:01.746161Z",
          "iopub.status.idle": "2025-04-07T05:24:19.238485Z",
          "shell.execute_reply.started": "2025-04-07T05:24:01.746135Z",
          "shell.execute_reply": "2025-04-07T05:24:19.237738Z"
        },
        "id": "ssvkWVPoqHct",
        "outputId": "37eaab88-ceeb-4e14-c524-7e1d6c9ea8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.51G/1.51G [00:28<00:00, 55.9MiB/s]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unsloth"
      ],
      "metadata": {
        "id": "1K08VpbLqHcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:24:19.239691Z",
          "iopub.execute_input": "2025-04-07T05:24:19.240199Z",
          "iopub.status.idle": "2025-04-07T05:25:41.206689Z",
          "shell.execute_reply.started": "2025-04-07T05:24:19.240165Z",
          "shell.execute_reply": "2025-04-07T05:25:41.205668Z"
        },
        "id": "uBnHnCHMqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "import os\n",
        "import base64\n",
        "import tempfile\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_socketio import SocketIO"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:25:41.207694Z",
          "iopub.execute_input": "2025-04-07T05:25:41.207984Z",
          "iopub.status.idle": "2025-04-07T05:25:54.321035Z",
          "shell.execute_reply.started": "2025-04-07T05:25:41.207957Z",
          "shell.execute_reply": "2025-04-07T05:25:54.320206Z"
        },
        "id": "Da3IVGYKqHcu",
        "outputId": "ab0d186a-2749-412a-8691-7849898ad8b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling the Fine Tuned Model from Hugging Face"
      ],
      "metadata": {
        "id": "vuugBN1OqHcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"tsa_oral_cancer_data_extraction_Meta-Llama-3.1-8B-bnb-4bit_10e\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:25:54.32187Z",
          "iopub.execute_input": "2025-04-07T05:25:54.322166Z",
          "iopub.status.idle": "2025-04-07T05:25:54.325995Z",
          "shell.execute_reply.started": "2025-04-07T05:25:54.322139Z",
          "shell.execute_reply": "2025-04-07T05:25:54.325024Z"
        },
        "id": "UoYi9NEKqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 14336 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:25:54.326943Z",
          "iopub.execute_input": "2025-04-07T05:25:54.327203Z",
          "iopub.status.idle": "2025-04-07T05:25:54.342698Z",
          "shell.execute_reply.started": "2025-04-07T05:25:54.32718Z",
          "shell.execute_reply": "2025-04-07T05:25:54.341791Z"
        },
        "id": "wjBgfn8dqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=f\"NishithP2004/{model_name}\",  # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length=max_seq_length,\n",
        "        dtype=dtype,\n",
        "        load_in_4bit=load_in_4bit\n",
        "    )\n",
        "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:25:54.346348Z",
          "iopub.execute_input": "2025-04-07T05:25:54.346612Z",
          "iopub.status.idle": "2025-04-07T05:26:27.251149Z",
          "shell.execute_reply.started": "2025-04-07T05:25:54.346589Z",
          "shell.execute_reply": "2025-04-07T05:26:27.250253Z"
        },
        "id": "GmytmY6PqHcu",
        "outputId": "c98fbd9a-558a-4cd5-ab41-022f14f4501c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d4e65fbd9a974705855efa6825e6edc6",
            "63e325aaa3ee4081aaf627e46ef162fa",
            "7b8f0ec9acd748a29f2d808cfa3405ac",
            "5464be164b3a4b02b42a56168ada8d3d",
            "020d7edb176b4ea6bd2f7e285f14c2cd",
            "2cd1a4695e5e47399cb4d4bf9de4785f",
            "19da1abbb1674e22b99d406f4ae02249",
            "de70fda9bc05473f856e93e91dfcea93",
            "34fab13b411d4ef989845be4b9190027",
            "f536cf9e6b3f434fbff86a8129620be0",
            "7aee699f25664714a712c36f211c50ec",
            "2685f2d0828444e39f40dd13c858ab76",
            "6c1fbda83f0947219c979e2ed32f80f9",
            "5f085f84f7994d518fc608a4a93e09e1",
            "37a906e90de445b0add0115aa4f8f605",
            "dae5a13d521f4c178024f7060c248436",
            "0b6d8bf018bb49418142012f550daa52",
            "8c8d21e140a2497ba9579b49a0a2fe55",
            "25b46b315ae64139a1a542b56d899afa",
            "63760cd1558043d78fc5ca133f31937f",
            "52a37bb3101c48a2a8b77fbcb6bbd25e",
            "097457c42fcb46eda4d99db97b677b61",
            "9b637c1fc1cb4946ab44b4eef74a5c29",
            "860b1cdd90a942dc8b0df2fc54b221fc",
            "c7410b0e8a0b49eb9c17ad24ef1ad6ef",
            "28661b4840584e9d86f036952938199c",
            "8819a3621a45460cb690f4fdd94cdcf2",
            "c6c6a6a9be9a43e99a2d35cfbd565136",
            "98933a123e94465b9a3f7fc6fbbcfe1b",
            "5d160616a55e4337b4d2827e13195273",
            "b5c84f8669cd454a86ad8a4c8c74c2a3",
            "af462ecc90134147beafcfea71edccbd",
            "3a06fc411c4f449e9efb1ed5d2c4742f",
            "6ea8edf1350b4567b2c143542b78a8e4",
            "f1816a5775ad42d7818a19d17fdee3d9",
            "97d33642d64940fe8d0abd521bd8aa2b",
            "e6462913bd1c4956b7bc5e77635af957",
            "74820137eab141e7aa8cf4476dc4646c",
            "d246dba4a5cf4182a7a33218bc9941f2",
            "972d74c8f2aa4cb2901c0e397d931592",
            "3ed67ed8ce1b4fd5863a8ad68380ee23",
            "11293dec18044f0c8ab9b674269925a3",
            "82f7a99113704175950d8dae8cda8d64",
            "90a309b952fd4a228360481355d9d810",
            "445de90eeaa141f082da3dbb717e17e7",
            "911b30abf4a9408c98bc9d93460d9d67",
            "df41dba975634a5694e78c093d82a980",
            "88033e32340744e5ae26b2a43fce9995",
            "a8275ead9eed4a70a4d194ea251885b5",
            "b8998e00c56b49f0a8f4f34c0defba98",
            "d77116ddd8574c5bbb3068cd191eba1a",
            "529c9268c58f408dbdf10744fa947ce7",
            "6f285060bdc54a6ab454adb5f557c005",
            "7171882dc42f4d5aab693a14c8903883",
            "337c7d17afbc418a9a5eb0be1162bc22",
            "bf1223c823b04337b306459b38d4ff04",
            "f261e958473441528ab11994f2d03926",
            "df7a0dc53cf74c9aab8a496861405d0f",
            "0c5e8bbc1f96405bb3be3113c21fb2ed",
            "66ea58de3d7d4987a07930c8d45cc5fb",
            "6aa8597f96494dc48c8545bb9e5b7d3d",
            "4a923ee8e5394cdcbdb2c759fd144e4e",
            "9aafcebb536b4ffa9cc38b08ec57ce88",
            "9f8b658d79c042319704357927881ba3",
            "0a683afcde61445fb2e092ad839d28ee",
            "ca725302dccc4b66b41d5ae612e43683"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.5.6: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4e65fbd9a974705855efa6825e6edc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/235 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2685f2d0828444e39f40dd13c858ab76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b637c1fc1cb4946ab44b4eef74a5c29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ea8edf1350b4567b2c143542b78a8e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "445de90eeaa141f082da3dbb717e17e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf1223c823b04337b306459b38d4ff04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alpaca Prompt Template"
      ],
      "metadata": {
        "id": "bC6fuiCmqHcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:26:27.252435Z",
          "iopub.execute_input": "2025-04-07T05:26:27.252789Z",
          "iopub.status.idle": "2025-04-07T05:26:27.256135Z",
          "shell.execute_reply.started": "2025-04-07T05:26:27.252744Z",
          "shell.execute_reply": "2025-04-07T05:26:27.255331Z"
        },
        "id": "GQZPLKPFqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Extract the essential details from the provided text containing a patient’s oral cancer data. Format the output as a semi-colon separated list of key-value pairs, strictly adhering to the following structure:\\nfeature1:value1;feature2:value2;… \\nExample: age:40;sex:1;subsite:2;Pathology:3;… \\nEnsure precise and efficient extraction by applying the given mappings accurately.\\nMappings: 1. age\\n2. sex: {male: 1, female: 2}\\n3. subsite: {tongue: 1, BM: 2, FOM: 3, alveolus: 4, hard palate: 5, RMT: 6, lips: 7}\\n4. pathology: {WDSCC: 1, Verrucous: 2, MDSCC: 3, PDSCC: 4, others: 5, ca in situ: 6}\\n5. clinicalT8thed: {T1: 1, T2: 2, T3: 3, T4a: 4, T4b: 5}\\n6. nodal8thed: {No nodes: 0, N1: 1, N2a: 2, N2b: 3, N2c: 4, N3a: 5, N3b: 6}\\n7. pt8thed: {T1: 1, T2: 2, T3: 3, T4a: 4, T4b: 5}\\n8. pN8thed: {N0: 0, N1: 1, N2a: 2, N2b: 3, N2c: 4, N3a: 5, N3b: 6}\\n9. PNI: {no: 0, yes: 1}\\n10. LVI: {no: 0, yes: 1}\\n11. Margins: {negative: 0, close: 1, positive: 2}\\n12. Boneinv: {no: 0, yes: 1}\\n13. skininv: {no: 0, yes: 1}\\n14. ENS: {no: 0, yes: 1}\\n15. Surgery: {SND 1-3: 1, SND 1-4: 2, MRND: 3, RND: 4}\\n16. lateralitysurgery: {ipsilateral: 1, bilateral: 2}\\n17. DOS\\n18. adjRx: {no: 0, yes: 1}\\n19. date of LR\\n20. Nodalrecurrencelevel: {ipsilateral: 1, contralateral: 2}\\n21. Nodallevel\\n22. date of Nodalrecurrence\\n23. last FU\\n24. stateFU: {NED: 1, AWD: 2, DWD': 3, Dead due to other causes: 4}\\nFullforms \\n1. BM – Buccal Mucosa\\n2. FOM – Floor of Mouth\\n3. RMT – Retromolar Trigone\\n4. WDSCC – Well-Differentiated Squamous Cell Carcinoma\\n5. MDSCC – Moderately Differentiated Squamous Cell Carcinoma\\n6. PDSCC – Poorly Differentiated Squamous Cell Carcinoma\\n7. PNI – Perineural Invasion\\n8. LVI – Lymphovascular Invasion\\n9. ENS – Extracapsular Nodal Spread\\n10. SND – Selective Neck Dissection\\n11. MRND – Modified Radical Neck Dissection\\n12. RND – Radical Neck Dissection\\n13. DOS – Date of Surgery\\n14. adjRx – Adjuvant Therapy\\n15. date of LR – Date of Local Recurrence\\n16. last FU – Date of Last Follow-Up\\n17. state FU – State at Last Follow-Up\\n18. Verrucous - Verrucous Carcinoma\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:26:27.256993Z",
          "iopub.execute_input": "2025-04-07T05:26:27.257288Z",
          "iopub.status.idle": "2025-04-07T05:26:27.27163Z",
          "shell.execute_reply.started": "2025-04-07T05:26:27.257253Z",
          "shell.execute_reply": "2025-04-07T05:26:27.270922Z"
        },
        "id": "gUqbgPNZqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:26:27.27249Z",
          "iopub.execute_input": "2025-04-07T05:26:27.272731Z",
          "iopub.status.idle": "2025-04-07T05:26:27.289725Z",
          "shell.execute_reply.started": "2025-04-07T05:26:27.272711Z",
          "shell.execute_reply": "2025-04-07T05:26:27.288983Z"
        },
        "id": "wpH1MmMgqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helpful Functions"
      ],
      "metadata": {
        "id": "Rk6tdLsVun1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_output(output_string):\n",
        "    \"\"\"Processes a single output string, splitting by ';' and then ':'.\n",
        "    Returns a dictionary with key-value pairs from the string.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    if pd.isna(output_string) or output_string == '': # handle missing or empty strings\n",
        "        return result\n",
        "\n",
        "    for item in output_string.split(';'):\n",
        "        try:\n",
        "            key, value = item.split(':', 1)  # Split at the first ':'\n",
        "            result[key.strip()] = value.strip()\n",
        "        except ValueError:  # Handle cases where there's no ':'\n",
        "            print(f\"Skipping malformed item: {item}\")\n",
        "    return result\n",
        "\n",
        "def process_model_output(output_string):\n",
        "    \"\"\"Extracts the response from the model's generated output.\"\"\"\n",
        "    try:\n",
        "        print(\"Output: \", output_string)\n",
        "        output_string = output_string.split(\"### Response:\\n\")[1].split(EOS_TOKEN)[0]\n",
        "    except IndexError:\n",
        "        print(\"Warning: Unexpected output format. Returning empty dictionary.\")\n",
        "        return {}\n",
        "    return process_output(output_string)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:26:27.290468Z",
          "iopub.execute_input": "2025-04-07T05:26:27.290717Z",
          "iopub.status.idle": "2025-04-07T05:26:27.303509Z",
          "shell.execute_reply.started": "2025-04-07T05:26:27.290684Z",
          "shell.execute_reply": "2025-04-07T05:26:27.302778Z"
        },
        "id": "KBtDYgPWqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(text):\n",
        "    input_text = alpaca_prompt.format(instruction, text, \"\")\n",
        "    inputs = tokenizer([input_text], return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=256, use_cache=True)\n",
        "    generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    result_dict = process_model_output(generated_text)\n",
        "    print(result_dict)\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "Kh3Vsz891Srk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarise Function"
      ],
      "metadata": {
        "id": "Z9_sLaNxJnOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\n",
        "    \"DOS\", \"Pathology\", \"Surgery\", \"adjRx\", \"age\", \"clinicalT8thed\", \"dateofLR\",\n",
        "    \"dateofNodalrecurrence\", \"lastFU\", \"lateralitysurgery\", \"nodal8thed\",\n",
        "    \"nodallevel\", \"pN8thed\", \"pt8thed\", \"sex\", \"stateFU\", \"subsite\"\n",
        "]"
      ],
      "metadata": {
        "id": "NVVzZd5ALU3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import asyncio\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are an expert oncologist.\n",
        "Given a raw summary generated by extracting key features from a patient's historical medical records and progress notes, your task is to synthesize a coherent, grammatically accurate narrative that clearly describes the progression of oral cancer in the patient.\n",
        "\n",
        "Present your output strictly in the following JSON format:\n",
        "\n",
        "{\n",
        "  \"summary\": \"\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "feature_value_map = {\n",
        "    \"age\": None,\n",
        "    \"sex\": {1: \"male\", 2: \"female\"},\n",
        "    \"subsite\": {\n",
        "        1: \"tongue\", 2: \"Buccal Mucosa\", 3: \"Floor of Mouth\", 4: \"alveolus\",\n",
        "        5: \"hard palate\", 6: \"Retromolar Trigone\", 7: \"lips\"\n",
        "    },\n",
        "    \"Pathology\": {\n",
        "        1: \"Well-Differentiated Squamous Cell Carcinoma\", 2: \"Verrucous Carcinoma\",\n",
        "        3: \"Moderately Differentiated Squamous Cell Carcinoma\",\n",
        "        4: \"Poorly Differentiated Squamous Cell Carcinoma\",\n",
        "        5: \"others\", 6: \"ca in situ\"\n",
        "    },\n",
        "    \"clinicalT8thed\": {1: \"T1\", 2: \"T2\", 3: \"T3\", 4: \"T4a\", 5: \"T4b\"},\n",
        "    \"nodal8thed\": {0: \"No nodes\", 1: \"N1\", 2: \"N2a\", 3: \"N2b\", 4: \"N2c\", 5: \"N3a\", 6: \"N3b\"},\n",
        "    \"pt8thed\": {1: \"T1\", 2: \"T2\", 3: \"T3\", 4: \"T4a\", 5: \"T4b\"},\n",
        "    \"pN8thed\": {0: \"N0\", 1: \"N1\", 2: \"N2a\", 3: \"N2b\", 4: \"N2c\", 5: \"N3a\", 6: \"N3b\"},\n",
        "    \"PNI\": {0: \"no\", 1: \"yes\"},\n",
        "    \"LVI\": {0: \"no\", 1: \"yes\"},\n",
        "    \"Margins\": {0: \"negative\", 1: \"close\", 2: \"positive\"},\n",
        "    \"Boneinv\": {0: \"no\", 1: \"yes\"},\n",
        "    \"skininv\": {0: \"no\", 1: \"yes\"},\n",
        "    \"ENS\": {0: \"no\", 1: \"yes\"},\n",
        "    \"Surgery\": {\n",
        "        1: \"Selective Neck Dissection 1-3\",\n",
        "        2: \"Selective Neck Dissection 1-4\",\n",
        "        3: \"Modified Radical Neck Dissection\",\n",
        "        4: \"Radical Neck Dissection\"\n",
        "    },\n",
        "    \"lateralitysurgery\": {1: \"ipsilateral\", 2: \"bilateral\"},\n",
        "    \"DOS\": None,\n",
        "    \"adjRx\": {0: \"no\", 1: \"yes\"},\n",
        "    \"dateofLR\": None,\n",
        "    \"Nodalrecurrencelevel\": {1: \"ipsilateral\", 2: \"contralateral\"},\n",
        "    \"Nodallevel\": None,\n",
        "    \"dateofNodalrecurrence\": None,\n",
        "    \"lastFU\": None,\n",
        "    \"stateFU\": {\n",
        "        1: \"No Evidence of Disease\",\n",
        "        2: \"Alive With Disease\",\n",
        "        3: \"Died With Disease\",\n",
        "        4: \"Dead due to other causes\"\n",
        "    }\n",
        "}\n",
        "\n",
        "feature_name_map = {\n",
        "    \"age\": \"age\",\n",
        "    \"sex\": \"sex\",\n",
        "    \"subsite\": \"subsite\",\n",
        "    \"Pathology\": \"pathology\",\n",
        "    \"clinicalT8thed\": \"Clinical Tumourstaging, according to 8th Edition\",\n",
        "    \"nodal8thed\": \"Nodal staging according to 8th edition\",\n",
        "    \"pt8thed\": \"Pathological T staging according to Eighth edition\",\n",
        "    \"pN8thed\": \"Pathological N staging According to 8, edition\",\n",
        "    \"PNI\": \"Perineural Invasion\",\n",
        "    \"LVI\": \"Lymphovascular Invasion\",\n",
        "    \"Margins\": \"Margin status\",\n",
        "    \"Boneinv\": \"Bone invasion\",\n",
        "    \"skininv\": \"Skin invasion\",\n",
        "    \"ENS\": \"Extracapsular Nodal Spread\",\n",
        "    \"Surgery\": \"Surgery\",\n",
        "    \"lateralitysurgery\": \"Laterality surgery\",\n",
        "    \"DOS\": \"Date of Surgery\",\n",
        "    \"adjRx\": \"Adjuvant Therapy\",\n",
        "    \"dateofLR\": \"Date of Local Recurrence\",\n",
        "    \"Nodalrecurrencelevel\": \"Nodal recurrence level\",\n",
        "    \"Nodallevel\": \"Nodal level\",\n",
        "    \"dateofNodalrecurrence\": \"Date of Nodal recurrence\",\n",
        "    \"lastFU\": \"Date of Last Follow-Up\",\n",
        "    \"stateFU\": \"State at Last Follow-Up\"\n",
        "}\n",
        "\n",
        "\n",
        "def reverse_map(row):\n",
        "    \"\"\"Convert a dictionary of features to a natural language prompt\"\"\"\n",
        "    summary_parts = []\n",
        "    for key, val in row.items():\n",
        "        if val is None or str(val).strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        readable_key = feature_name_map.get(key, key)\n",
        "        mapped_value = feature_value_map.get(key)\n",
        "\n",
        "        if isinstance(mapped_value, dict):\n",
        "            readable_value = mapped_value.get(int(val), val)\n",
        "        else:\n",
        "            readable_value = val\n",
        "\n",
        "        summary_parts.append(f\"{readable_key}: {readable_value}\")\n",
        "\n",
        "    return \" \".join(summary_parts)\n",
        "\n",
        "\n",
        "async def summarise(row: dict, model: str = \"gemma3:4b\", attempt: int = 1) -> str:\n",
        "    try:\n",
        "        raw_prompt = reverse_map(row)\n",
        "        print(f\"[Prompt]: {raw_prompt}\")\n",
        "\n",
        "        response = ollama.generate(\n",
        "            model=model,\n",
        "            system=system_prompt,\n",
        "            prompt=raw_prompt,\n",
        "            options = { 'temperature': 0.7 },\n",
        "            format=\"json\"\n",
        "        )\n",
        "\n",
        "        summary_text = json.loads(response['response']).get(\"summary\", \"\")\n",
        "        if not summary_text and attempt < 3:\n",
        "            print(f\"[!] Empty summary. Retrying (attempt {attempt + 1})...\")\n",
        "            return await summarise(row, model, attempt + 1)\n",
        "\n",
        "        return summary_text or \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in summarise: {str(e)}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "jMoXO1hdJpQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI Chat (RAG) + Document QA"
      ],
      "metadata": {
        "id": "Im1vl7ZOv-6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ollama_model = models[0]\n",
        "\n",
        "def chat(user_prompt):\n",
        "  prompt = user_prompt\n",
        "\n",
        "  response = ollama.generate(model=ollama_model, prompt=prompt, options={ \"temperature\": 0.7 })\n",
        "  return response[\"response\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:50:00.80567Z",
          "iopub.execute_input": "2025-04-07T05:50:00.80599Z",
          "iopub.status.idle": "2025-04-07T05:50:00.810247Z",
          "shell.execute_reply.started": "2025-04-07T05:50:00.805965Z",
          "shell.execute_reply": "2025-04-07T05:50:00.809393Z"
        },
        "id": "D-gnd6WcqHcu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs = text_splitter.create_documents(documents)\n",
        "    return docs"
      ],
      "metadata": {
        "id": "4g8T6LqMv65F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "embeddings = OllamaEmbeddings(model=models[1], base_url=\"http://localhost:11434\")"
      ],
      "metadata": {
        "id": "J0PVMJZCu9tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "llm = ChatOllama(model=models[0], base_url=\"http://localhost:11434\")"
      ],
      "metadata": {
        "id": "pxkYuGpywZRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"patient_records\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")"
      ],
      "metadata": {
        "id": "7BToRsLMvPLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "template = \"Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "lRr_MMIFv721"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_ai(query, session_id):\n",
        "    docs = vector_store.similarity_search(query, k=3, filter= {\n",
        "        \"session_id\": session_id\n",
        "    })\n",
        "    context = \" \".join([d.page_content for d in docs])\n",
        "\n",
        "    response = llm.invoke(prompt.format_prompt(context=context, question=query).to_messages())\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "8rk5e-jwFjEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Write me a song on Time Series Analysis of Oral Cancer Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "Vt77cHe56HUP",
        "outputId": "be6a7fdf-5a78-44be-fd81-55a24be1ac19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, here's a song about Time Series Analysis of Oral Cancer Data, aiming for a blend of informative and slightly melodic. It’s written with a focus on the concepts and challenges involved.\\n\\n**Title: The Rhythm of the Risk**\\n\\n(Intro - Gentle, slightly unsettling synth chords and a slow, deliberate drum beat)\\n\\n(Verse 1)\\nThe gums, the tongue, a silent plea,\\nA subtle shift, for all to see.\\nOral cancer, a creeping threat,\\nWe’re hunting patterns, haven't finished yet.\\nCollecting data, day by day,\\nPatient records in a careful way.\\nTime series analysis, our guiding light,\\nTo spot the changes, sharp and bright.\\n\\n(Chorus - Builds slightly, adding a subtle bass line)\\nIt’s the rhythm of the risk, a temporal flow,\\nLooking at trends, where the numbers go.\\nFrom biopsies done to symptoms shown,\\nUnlocking secrets, clearly known.\\nWe're charting the rise, the peaks, the fall,\\nTo understand the danger, heed the call.\\n\\n\\n(Verse 2)\\nWe’ve got the incidence rates, a monthly climb,\\nOr maybe a plateau, a moment of time.\\nLooking for seasonality, a pattern true,\\nPerhaps linked to weather, or something new.\\nWe’re checking for autocorrelation's embrace,\\nPast values predicting the current space.\\nLagged variables, a crucial key,\\nTo reveal the connections, for you and me.\\n\\n(Chorus - Slightly stronger, with layered vocals)\\nIt’s the rhythm of the risk, a temporal flow,\\nLooking at trends, where the numbers go.\\nFrom biopsies done to symptoms shown,\\nUnlocking secrets, clearly known.\\nWe're charting the rise, the peaks, the fall,\\nTo understand the danger, heed the call.\\n\\n(Bridge -  Tempo slows slightly, more reflective)\\nARIMA models, a powerful tool,\\nTo forecast the future, break the rule.\\nStationarity tests, a critical test,\\nTo ensure our models are truly blessed.\\nDealing with outliers, a careful hand,\\nTo keep the analysis steady and grand.\\n\\n(Instrumental Break -  A short, synthesized melody representing the fluctuating data)\\n\\n(Verse 3)\\nGeographic factors, we must consider,\\nPopulation density, a growing endeavor.\\nSocial determinants, a vital part,\\nSmoking, alcohol, a breaking heart.\\nCombining the data, a holistic view,\\nTo predict the outbreaks, fresh and new.\\n\\n(Chorus - Full instrumentation, powerful and driving)\\nIt’s the rhythm of the risk, a temporal flow,\\nLooking at trends, where the numbers go.\\nFrom biopsies done to symptoms shown,\\nUnlocking secrets, clearly known.\\nWe're charting the rise, the peaks, the fall,\\nTo understand the danger, heed the call.\\n\\n(Outro -  Music fades slowly, returning to the initial synth chords)\\nTime series analysis, a watchful eye,\\nProtecting our mouths, beneath the sky. \\n(Final synth chord sustains)\\n\\n\\n\\n---\\n\\n**Notes and Considerations:**\\n\\n*   **Genre:**  This leans towards a slightly electronic/ambient sound, suitable for conveying a scientific and analytical feel.\\n*   **Instrumentation:**  Synths, subtle drum beats, bass lines, and potentially some string pads would be effective.\\n*   **Vocals:**  A clear, informative vocal style would be best.\\n*   **Complexity:**  I’ve tried to incorporate key terms (ARIMA, autocorrelation, stationarity) but kept the lyrics accessible.\\n*   **Accuracy:**  I've focused on conveying the *concepts* of time series analysis in this context.\\n\\nTo help me refine this further, could you tell me:\\n\\n*   What specific aspects of time series analysis are most important to highlight in the song? (e.g., specific forecasting models, data preprocessing, or the importance of visualising trends)\\n*   What is the intended audience for this song? (e.g., medical students, researchers, the general public?)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flask Server"
      ],
      "metadata": {
        "id": "_1Mti1dvqHcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_in_background(\"ollama serve\")\n",
        "\n",
        "app = Flask(__name__)\n",
        "socketio = SocketIO(app, cors_allowed_origins=\"*\")\n",
        "\n",
        "# Set up ngrok tunnel\n",
        "public_url = ngrok.connect(5000, domain=domain.replace(\"https://\", \"\")).public_url\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"Socket.IO Speech-to-Text Server Running!\"\n",
        "\n",
        "@app.route(\"/extract\", methods=[\"POST\"])\n",
        "def extract():\n",
        "    data = request.get_json()\n",
        "    if not data or \"text\" not in data:\n",
        "        return jsonify({\"error\": \"Invalid input. Expected JSON with 'text' field.\"}), 400\n",
        "\n",
        "    vector_store.add_documents([Document(page_content=data[\"text\"], metadata = {\n",
        "        \"session_id\": data.get(\"session_id\", \"\")\n",
        "    })])\n",
        "\n",
        "    response = extract_features(data[\"text\"])\n",
        "    return jsonify({\"response\": response})\n",
        "\n",
        "'''\n",
        "@socketio.on(\"chat_interaction\")\n",
        "def handle_chat_interaction(data, session_id):\n",
        "    \"\"\"\n",
        "    Handles both text and audio-based chat input.\n",
        "    - If `data[\"text\"]` is present, it processes the text directly.\n",
        "    - If `data[\"audio\"]` is present, it decodes and transcribes audio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if \"text\" in data:\n",
        "            message = data[\"text\"]\n",
        "            if not message.strip():\n",
        "                socketio.emit(\"chat_error\", {\"error\": \"Empty text provided.\"})\n",
        "                return\n",
        "\n",
        "            print(f\"Received text message: {message}\")\n",
        "\n",
        "            response = graph.invoke({ \"question\": message }, config={ \"configurable\": {\n",
        "                \"search_kwargs\": {\n",
        "                    \"namespace\": session_id\n",
        "                }\n",
        "            }})\n",
        "            print(f\"Chat Response: {response}\")\n",
        "\n",
        "            socketio.emit(\"chat_response\", {\n",
        "                \"input_type\": \"text\",\n",
        "                \"original_message\": message,\n",
        "                \"response\": response\n",
        "            })\n",
        "\n",
        "        elif \"audio\" in data:\n",
        "            print(\"Processing audio input...\")\n",
        "            audio_data = base64.b64decode(data[\"audio\"])\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio:\n",
        "                temp_audio.write(audio_data)\n",
        "                temp_audio_path = temp_audio.name\n",
        "\n",
        "            print(\"Transcribing audio...\")\n",
        "            result = whisper_model.transcribe(temp_audio_path)\n",
        "            text = result[\"text\"]\n",
        "            detected_lang = result[\"language\"]\n",
        "            print(f\"Transcription: {text}\")\n",
        "\n",
        "            print(\"Translating audio to English...\")\n",
        "            translation_result = whisper_model.transcribe(temp_audio_path, language=\"en\", task=\"translate\")\n",
        "            translated_text = translation_result[\"text\"]\n",
        "            print(f\"Translation: {translated_text}\")\n",
        "\n",
        "            print(\"Generating Chat Response...\")\n",
        "            chat_response = graph.invoke({ \"question\": text }, config={ \"configurable\": {\n",
        "                \"search_kwargs\": {\n",
        "                    \"namespace\": session_id\n",
        "                }\n",
        "            }})\n",
        "            print(f\"Chat Response: {chat_response}\")\n",
        "\n",
        "            socketio.emit(\"chat_response\", {\n",
        "                \"input_type\": \"audio\",\n",
        "                \"detected_language\": detected_lang,\n",
        "                \"transcribed_text\": text,\n",
        "                \"translated_text\": translated_text,\n",
        "                \"response\": chat_response\n",
        "            })\n",
        "\n",
        "            os.remove(temp_audio_path)\n",
        "\n",
        "        else:\n",
        "            socketio.emit(\"chat_error\", {\"error\": \"Invalid input. Provide either 'text' or 'audio'.\"})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_interaction: {e}\")\n",
        "        socketio.emit(\"chat_error\", {\"error\": str(e)})\n",
        "\n",
        "@socketio.on(\"summarise_features\")\n",
        "def handle_summarise_features(data, session_id):\n",
        "    \"\"\"\n",
        "    Handle summarise request via socket.io using only the allowed feature keys in `cols`.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not isinstance(data, dict) or not data:\n",
        "            socketio.emit(\"summarise_error\", {\"error\": \"Invalid data format. Expected JSON object.\"})\n",
        "            return\n",
        "\n",
        "        # Filter only allowed features\n",
        "        filtered_data = {key: data[key] for key in cols if key in data and data[key] not in [None, \"\"]}\n",
        "\n",
        "        if not filtered_data:\n",
        "            socketio.emit(\"summarise_error\", {\"error\": \"No valid features found in input.\"})\n",
        "            return\n",
        "\n",
        "        print(f\"[Session {session_id}] Processing features: {list(filtered_data.keys())}\")\n",
        "\n",
        "        # Run the async summarise function in a sync context\n",
        "        loop = asyncio.new_event_loop()\n",
        "        asyncio.set_event_loop(loop)\n",
        "        summary = loop.run_until_complete(summarise(filtered_data))\n",
        "        loop.close()\n",
        "\n",
        "        socketio.emit(\"summarise_result\", {\n",
        "            \"summary\": summary,\n",
        "            \"session_id\": session_id\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] summarise_features: {e}\")\n",
        "        socketio.emit(\"summarise_error\", {\"error\": str(e), \"session_id\": session_id})\n",
        "'''\n",
        "\n",
        "@app.route(\"/chat_interaction\", methods=[\"POST\"])\n",
        "def chat_interaction():\n",
        "    data = request.get_json()\n",
        "    session_id = request.args.get(\"session_id\", \"\")\n",
        "\n",
        "    if not data:\n",
        "        return jsonify({\"error\": \"No input data provided.\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Handle Text Input\n",
        "        if \"text\" in data:\n",
        "            message = data[\"text\"]\n",
        "            if not message.strip():\n",
        "                return jsonify({\"error\": \"Empty text provided.\"}), 400\n",
        "\n",
        "            print(f\"Received text message: {message}\")\n",
        "\n",
        "            response = chat_with_ai(message, session_id)\n",
        "            print(f\"Chat Response: {response}\")\n",
        "\n",
        "            return jsonify({\n",
        "                \"input_type\": \"text\",\n",
        "                \"original_message\": message,\n",
        "                \"response\": response\n",
        "            })\n",
        "\n",
        "        # Handle Audio Input\n",
        "        elif \"audio\" in data:\n",
        "            print(\"Processing audio input...\")\n",
        "            audio_data = base64.b64decode(data[\"audio\"])\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio:\n",
        "                temp_audio.write(audio_data)\n",
        "                temp_audio_path = temp_audio.name\n",
        "\n",
        "            print(\"Transcribing audio...\")\n",
        "            result = whisper_model.transcribe(temp_audio_path)\n",
        "            text = result[\"text\"]\n",
        "            detected_lang = result[\"language\"]\n",
        "            print(f\"Transcription: {text}\")\n",
        "\n",
        "            print(\"Translating audio to English...\")\n",
        "            translation_result = whisper_model.transcribe(temp_audio_path, language=\"en\", task=\"translate\")\n",
        "            translated_text = translation_result[\"text\"]\n",
        "            print(f\"Translation: {translated_text}\")\n",
        "\n",
        "            print(\"Generating Chat Response...\")\n",
        "            chat_response = chat_with_ai(text, session_id)\n",
        "            print(f\"Chat Response: {chat_response}\")\n",
        "\n",
        "            os.remove(temp_audio_path)\n",
        "\n",
        "            return jsonify({\n",
        "                \"input_type\": \"audio\",\n",
        "                \"detected_language\": detected_lang,\n",
        "                \"transcribed_text\": text,\n",
        "                \"translated_text\": translated_text,\n",
        "                \"response\": chat_response\n",
        "            })\n",
        "\n",
        "        else:\n",
        "            return jsonify({\"error\": \"Invalid input. Provide either 'text' or 'audio'.\"}), 400\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_interaction: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route(\"/summarise_features\", methods=[\"POST\"])\n",
        "def summarise_features():\n",
        "    data = request.get_json()\n",
        "    session_id = request.args.get(\"session_id\", \"\")\n",
        "\n",
        "    if not isinstance(data, dict) or not data:\n",
        "        return jsonify({\"error\": \"Invalid data format. Expected JSON object.\"}), 400\n",
        "\n",
        "    try:\n",
        "        filtered_data = {key: data[key] for key in cols if key in data and data[key] not in [None, \"\"]}\n",
        "\n",
        "        if not filtered_data:\n",
        "            return jsonify({\"error\": \"No valid features found in input.\"}), 400\n",
        "\n",
        "        print(f\"[Session {session_id}] Processing features: {list(filtered_data.keys())}\")\n",
        "\n",
        "        loop = asyncio.new_event_loop()\n",
        "        asyncio.set_event_loop(loop)\n",
        "        summary = loop.run_until_complete(summarise(filtered_data))\n",
        "        loop.close()\n",
        "\n",
        "        return jsonify({\n",
        "            \"summary\": summary,\n",
        "            \"session_id\": session_id\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] summarise_features: {e}\")\n",
        "        return jsonify({\"error\": str(e), \"session_id\": session_id}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    socketio.run(app, host=\"0.0.0.0\", port=5000, allow_unsafe_werkzeug=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T05:43:16.723437Z",
          "iopub.execute_input": "2025-04-07T05:43:16.72376Z",
          "iopub.status.idle": "2025-04-07T05:48:19.099031Z",
          "shell.execute_reply.started": "2025-04-07T05:43:16.723736Z",
          "shell.execute_reply": "2025-04-07T05:48:19.096961Z"
        },
        "id": "7l_nrOOpqHcv"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}